#!/usr/bin/env bash

CLIENTS=(16)
NODES=10
LASP_BRANCH=partisan
IMAGE=lasplang/lasp-partisan
DOCKERFILE=Dockerfiles/lasp-partisan
REPS=1
GCE=false
MACHINE="n1-highmem-16"
MAX_EVENTS=100000
BLOCKING_SYNC=false
EVENT_INTERVAL=0
JITTER=false
JITTER_PERCENT=1
SLOWDOWN=false

# Environment variables.
ENV_VARS=(
  JITTER
  JITTER_PERCENT
  STATE_INTERVAL
  SLOWDOWN
)

for ENV_VAR in "${ENV_VARS[@]}"
do
  if [ -z "${!ENV_VAR}" ]; then
    echo ">>> ${ENV_VAR} is not configured; please export it."
    exit 1
  fi
done

# Rebuild image if desired.
if [ ! -z "$REBUILD_IMAGE" ]; then
    # Delete image
    IMAGE_IDS=$(docker images | grep ${IMAGE} | awk '{print $3}')
    echo "Images matching for deletion: ${IMAGE_IDS}"

    if [ ! -z "$IMAGE_IDS" ]; then
      docker rmi ${IMAGE_IDS}
    fi

    # Rebuild image fresh, to ensure no stale dependencies
    docker build --no-cache -f ${DOCKERFILE} -t ${IMAGE} .

    # Push image to hub
    docker push ${IMAGE}
fi

# Perform cluster operations if necessary.
if [ ! -z "$CLUSTER_START" ]; then
  # Bootstrap cluster
  gcloud beta container clusters create lasp \
    --machine-type=${MACHINE} \
    --num-nodes=${NODES} \
    --enable-legacy-authorization

  # Get container credential
  gcloud beta container clusters get-credentials lasp
fi

echo "Removing initial labeling."
kubectl label nodes --all lasp_selector-

if [ ! -z "$REMOVE" ]; then
  echo "Removing deployments, services, pods, and replicasets."
  kubectl delete deployments --all
  kubectl delete replicasets --all
  kubectl delete services --all
  kubectl delete pods --all
fi

echo "Removing /tmp logs."
rm -rf /tmp/logs

if [ ! -z "$DELETE_LOGS" ]; then
  echo "Removing older logs."
  rm -rf priv/evaluation/logs
fi

# Allocate machines accordingly.
for i in ${CLIENTS[@]}; do
  # Find a machine we can allocate these to.
  AVAILABLE=$(kubectl get nodes -l '!lasp_selector' | grep -v master | grep Ready | head -1 | awk '{print $1}')

  # Label the node.
  kubectl label node ${AVAILABLE} lasp_selector=${i}

  echo "Labeled node ${AVAILABLE} for runs of ${i} clients."
done

# Allocate machine for redis.
AVAILABLE=$(kubectl get nodes -l '!lasp_selector' | grep -v master | grep Ready | head -1 | awk '{print $1}')
kubectl label node ${AVAILABLE} lasp_selector=redis
echo "Labeled node ${AVAILABLE} for runs of redis."

echo "Adding permissive permissions."
kubectl create clusterrolebinding permissive-binding \
  --clusterrole=cluster-admin \
  --user=admin \
  --user=kubelet \
  --user=system:anonymous \
  --group=system:serviceaccounts

# Deploy a single redis instance.
echo "Copying code to /tmp"
cp bin/sync-redis.erl /tmp
cp bin/kube-divergence /tmp
cp bin/event-interval /tmp
mkdir -p /tmp/_build/exp/lib/eredis/ebin
cp -Rp _build/exp/lib/eredis/ebin/* /tmp/_build/exp/lib/eredis/ebin

cd /tmp

cat <<EOF > redis.yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: redis
    labels:
      run: redis
  spec:
    type: LoadBalancer
    ports:
    - port: 6379
      protocol: TCP
      name: tcp
    selector:
      run: redis
---
  apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    name: redis
  spec:
    replicas: 1
    template:
      metadata:
        labels:
          run: redis
      spec:
        nodeSelector:
          lasp_selector: redis
        containers:
        - name: redis
          image: redis
EOF

echo "Creating redis deployment."
kubectl create -f /tmp/redis.yaml

while [ -z "$REDIS_RUNNING" ]; do
  REDIS_RUNNING=$(kubectl get pods | grep redis | grep Running)
  echo "Sleeping for redis deployment..."
  sleep 5
done

# Start the executions in parallel.
for k in ${CLIENTS[@]}; do

  if [ "$SLOWDOWN" = true ] ; then
    N=10
    EVENT_INTERVAL=$(N=${N} ./event-interval)
    MODIFIED_STATE_INTERVAL=$(expr ${N} \* ${STATE_INTERVAL})
  else
    N=1
    EVENT_INTERVAL=0
    MODIFIED_STATE_INTERVAL=${STATE_INTERVAL}
  fi

  echo "N: ${N}"
  echo "STATE_INTERVAL: ${STATE_INTERVAL}"
  echo "EVENT_INTERVAL: ${EVENT_INTERVAL}"
  echo "MODIFIED_STATE_INTERVAL: ${MODIFIED_STATE_INTERVAL}"

  echo "Launching client simulation: ${k} clients; state interval: ${MODIFIED_STATE_INTERVAL} event interval: ${EVENT_INTERVAL}"

  BLOCKING_SYNC=${BLOCKING_SYNC} \
    JITTER=${JITTER} \
    JITTER_PERCENT=${JITTER_PERCENT} \
    EVENT_INTERVAL=${EVENT_INTERVAL} \
    STATE_INTERVAL=${MODIFIED_STATE_INTERVAL} \
    MAX_EVENTS=${MAX_EVENTS} \
    REPS=${REPS} \
    LASP_BRANCH=${LASP_BRANCH} \
    IMAGE=${IMAGE} \
    GCE=${GCE} \
    DIVERGENCE_TYPE=gcounter \
    CLIENT_NUMBER=${k} \
    ./kube-divergence &
  sleep 10
done

# wait for all jobs to finish.
for job in `jobs -p`
do
  echo "Waiting on: $job"
  wait $job || let "FAIL+=1"
done

echo "Loop finished; tasks remain:"
kubectl get pods

echo "All tasks are finished."

# Download data from Redis at the end of the execution.
if [ "$GCE" == "true" ]; then
  echo "Running in Google Container Engine."
  export REDIS_SERVICE_HOST=$(kubectl get services | grep redis | awk '{print $3}' | head -1)
  # export REDIS_SERVICE_HOST=$(gcloud compute forwarding-rules list | grep TCP | awk '{print $3}' | tail -1)
  export REDIS_SERVICE_PORT=6379
else
  export REDIS_SERVICE_HOST=$(kubectl config view | grep server | cut -f 2- -d ":" | tr -d " " | head -1 | cut -f 2-2 -d ":" | sed -e 's/\/\///g')
  export REDIS_SERVICE_PORT=$(kubectl get service redis -o jsonpath="{.spec.ports[*].nodePort}")
fi

echo "REDIS_SERVICE_HOST: ${REDIS_SERVICE_HOST}"
echo "REDIS_SERVICE_PORT: ${REDIS_SERVICE_PORT}"

echo "Downloading data from Redis."
./sync-redis.erl
mkdir -p ~/lasp/priv/evaluation/logs
cp -Rp /tmp/logs/* ~/lasp/priv/evaluation/logs

# Terminate redis only if we explicitly say so, given sometimes we have
# to aggregate the logs later if for some instance we are being port
# filtered.
if [ ! -z "$REDIS_STOP" ]; then
  echo "Deleting redis deployments and servies."
  kubectl delete -f /tmp/redis.yaml
  echo
fi

# Perform cluster operations if necessary.
if [ ! -z "$CLUSTER_STOP" ]; then
  # Terminate the cluster
  yes | gcloud beta container clusters delete lasp
fi
